# VittoriaDB RAG Web UI

A complete ChatGPT-like web interface built with React + Streamlit, powered by VittoriaDB for advanced RAG capabilities.

## ğŸ¯ Features

- **ğŸ’¬ ChatGPT-like Interface**: Clean, modern chat UI with streaming responses
- **ğŸ“ File Upload & Processing**: Support for PDF, DOCX, TXT, MD, HTML files
- **ğŸŒ Web Research**: Real-time web search with automatic knowledge storage
- **ğŸ‘¨â€ğŸ’» GitHub Code Indexing**: Index and search through GitHub repositories
- **ğŸ§  RAG System**: Intelligent document retrieval and context-aware responses
- **âš¡ Real-time Streaming**: Live response streaming for better UX
- **ğŸ¨ Modern UI**: Built with React, shadcn/ui, and Tailwind CSS

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ React Frontend (Port 3000)                                 â”‚
â”‚ â”œâ”€ shadcn/ui components                                     â”‚
â”‚ â”œâ”€ Tailwind CSS styling                                     â”‚
â”‚ â””â”€ Real-time chat interface                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ HTTP/WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Streamlit Backend (Port 8501)                              â”‚
â”‚ â”œâ”€ File processing & upload                                 â”‚
â”‚ â”œâ”€ Web research integration                                 â”‚
â”‚ â”œâ”€ GitHub repository indexing                               â”‚
â”‚ â””â”€ LLM integration (OpenAI/Ollama)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ Python SDK
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VittoriaDB Server (Port 8080)                              â”‚
â”‚ â”œâ”€ Vector storage & search                                  â”‚
â”‚ â”œâ”€ Ollama embeddings (768D)                                â”‚
â”‚ â”œâ”€ Document collections                                     â”‚
â”‚ â””â”€ Semantic similarity search                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### ğŸ³ Docker Setup (Recommended)

The easiest way to run the complete RAG system with all dependencies:

```bash
# 1. Clone and navigate to the web UI directory
cd examples/web-ui-rag

# 2. Set up environment variables (secure approach)
export OPENAI_API_KEY=your_openai_api_key_here
export GITHUB_TOKEN=your_github_token_here  # optional
export OLLAMA_URL=http://ollama:11434        # optional

# 3. Start the development environment
./run-dev.sh
```

**What's included:**
- âœ… **VittoriaDB**: Vector database with HNSW indexing and I/O optimization (built locally)
- âœ… **Backend**: FastAPI with RAG, web research, and file processing
- âœ… **Frontend**: React UI with real-time chat interface
- âœ… **Ollama**: Local LLM inference (optional, for offline usage)
- âœ… **Chromium**: Web scraping with Playwright/Crawl4AI (fully configured)
- âœ… **Docker Compose**: Complete orchestration with health checks
- âœ… **No Redis**: Simplified architecture using FastAPI BackgroundTasks
- âœ… **Unified Configuration**: Advanced configuration management with environment variables

### ğŸ“‹ Environment Configuration

**ğŸ” Secure Environment Variable Setup:**

Set your API keys as system environment variables (recommended for security):

```bash
# Required for AI functionality
export OPENAI_API_KEY=your_openai_api_key_here

# Optional but recommended
export GITHUB_TOKEN=your_github_token_here    # For private repos and higher rate limits
export OLLAMA_URL=http://ollama:11434          # For local ML models

# Use the interactive setup script
./setup-env.sh

# Service URLs (default values work for Docker Compose)
VITTORIADB_URL=http://localhost:8080
OLLAMA_URL=http://localhost:11434
NEXT_PUBLIC_API_URL=http://localhost:8501
```

**Docker Compose Files:**
- `docker-compose.dev.yml` - Development with hot reload
- `docker-compose.yml` - Standard setup
- `docker-compose.prod.yml` - Production optimized

### ğŸ¯ Access Points

Once running, access the application at:

- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8501
- **VittoriaDB**: http://localhost:8080
- **Ollama**: http://localhost:11434

### ğŸ› ï¸ Manual Setup (Alternative)

If you prefer to run without Docker:

#### Prerequisites

```bash
# Install VittoriaDB Python SDK
pip install vittoriadb

# Install Ollama for local embeddings
curl -fsSL https://ollama.ai/install.sh | sh
ollama serve
ollama pull nomic-embed-text

# Install Node.js and npm
# https://nodejs.org/
```

#### Backend Setup

```bash
cd backend
pip install -r requirements.txt
streamlit run app.py
```

#### Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

## ğŸ“– Usage

1. **Start VittoriaDB**: The backend automatically starts VittoriaDB server
2. **Upload Files**: Drag & drop documents for automatic processing and indexing
3. **Web Research**: Ask questions that trigger web searches with automatic storage
4. **GitHub Indexing**: Provide GitHub repo URLs for code indexing
5. **Chat**: Ask questions and get context-aware responses from your knowledge base

## ğŸ› ï¸ Development

### Backend Structure
```
backend/
â”œâ”€â”€ app.py              # Main Streamlit application
â”œâ”€â”€ rag_system.py       # RAG logic and VittoriaDB integration
â”œâ”€â”€ file_processor.py   # Document processing utilities
â”œâ”€â”€ web_research.py     # Web search and scraping
â”œâ”€â”€ github_indexer.py   # GitHub repository indexing
â””â”€â”€ requirements.txt    # Python dependencies
```

### Frontend Structure
```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/     # React components
â”‚   â”œâ”€â”€ lib/           # Utilities and API clients
â”‚   â”œâ”€â”€ hooks/         # Custom React hooks
â”‚   â””â”€â”€ styles/        # Tailwind CSS styles
â”œâ”€â”€ package.json       # Node.js dependencies
â””â”€â”€ tailwind.config.js # Tailwind configuration
```

## ğŸ¨ UI Components

- **Chat Interface**: Message bubbles, typing indicators, streaming text
- **File Upload**: Drag & drop zone with progress indicators
- **Sidebar**: Knowledge base management, collection browser
- **Settings**: Model selection, embedding configuration
- **Research Panel**: Web search results and source citations

## ğŸ”§ Configuration

### Environment Variables

```bash
# Set environment variables (secure approach)
export OPENAI_API_KEY=your_openai_key_here
export GITHUB_TOKEN=your_github_token_here  # optional
export VITTORIADB_URL=http://localhost:8080
export OLLAMA_URL=http://localhost:11434

# Frontend environment (if running separately)
export NEXT_PUBLIC_API_URL=http://localhost:8501
```

## ğŸ³ Docker Architecture

The Docker setup includes several optimizations and fixes:

### âœ… **What's Fixed:**
- **Chromium Browser**: Fully configured with Playwright for web scraping
- **VittoriaDB Build**: Local build instead of non-existent external image
- **Redis Removed**: Simplified architecture using FastAPI BackgroundTasks
- **Vectorizer Config**: Proper collection initialization with embeddings
- **Build Optimization**: Reduced Docker context from 3.74GB â†’ 438KB
- **Go Version**: Updated to 1.24 to match project requirements

### ğŸ—ï¸ **Service Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend (React + Next.js)                    Port 3000    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ HTTP/WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend (FastAPI + Streamlit)                 Port 8501    â”‚
â”‚ â”œâ”€ RAG System with VittoriaDB integration                  â”‚
â”‚ â”œâ”€ Web Research with Chromium/Crawl4AI                     â”‚
â”‚ â”œâ”€ File Processing (PDF, DOCX, TXT, MD, HTML)              â”‚
â”‚ â””â”€ GitHub Repository Indexing                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ Python SDK
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VittoriaDB (Local Build)                      Port 8080    â”‚
â”‚ â”œâ”€ Vector Storage with HNSW Indexing                       â”‚
â”‚ â”œâ”€ OpenAI/Ollama Embeddings Integration                    â”‚
â”‚ â””â”€ ACID-compliant Persistence                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Performance

- **File Processing**: ~1-2 seconds per document
- **Web Research**: ~20-30 seconds per query (with Chromium rendering)
- **Vector Search**: <100ms response time
- **Chat Response**: ~1-3 seconds with streaming
- **Docker Build**: ~2-3 minutes (with caching)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

MIT License - see [LICENSE](../../LICENSE) file for details.
